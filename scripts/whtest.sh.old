#!/usr/bin/python

# ----------------------------------------------------------------------------
#                 Copyright (c) 1996-2009 AT&T
#                      All Rights Reserved
#  THIS IS UNPUBLISHED PROPRIETARY SOURCE DOCUMENTATION OF AT&T
#        The copyright notice above does not evidence any
#         actual or intended publication of such source.
#
# change history:
#
#      02/01/2009  (Iker Arizmendi)      created
#
# ----------------------------------------------------------------------------

PROG_NAME = "whtest"
PROG_VERSION = "1.0"

# ============================================================================
# documentation
#
doc = '''
-----------------------------------------------------------------------------
OVERVIEW
-----------------------------------------------------------------------------
whtest is a tool for simulating one or more concurrent HTTP clients that
issue requests to a given URL. The tool supports HTTP GET and streaming
HTTP POST requests. In its simplest form, whtest can be used to issue an
HTTP GET as follows:
    
    $ whtest http://my/url

where the first argument is the URL one wishes to test. To stream a single
file to a server via POST the following is used instead:

    $ whtest http://my/url --mode=stream --input=myfile

By default whtest will stream the file at a rate of 385 bytes every 0.25
seconds (ie, AMR encoding); the --chunk-bytes and --chunk-interval options
can be used to change the rate as appropriate. 

To simulate more than one concurrent client or to issue the same request
more than once whtest provides --num-threads, --min-req and --req-delay
switches. Eg, 

    $ whtest http://my/url --mode=stream   \\
                           --input=myfile  \\
                           --num-threads=5 \\
                           --min-req=10    \\
                           --req-delay=0.5

This example will simulate 5 clients (ie, threads) each of which will issue
the request 10 times with a random 0-0.5 second delay between each request.

-----------------------------------------------------------------------------
INPUT LISTS
-----------------------------------------------------------------------------
whtest can also accept lists of inputs. Eg, 

    $ whtest http://my/url --mode=stream --list=mylist

whtest will issue one request to the server for each item in the input
list; because the mode is "stream" whtest will interpret each item as
the path to a file which is to be streamed via POST. 

For HTTP GET queries the input list is interpreted differently. Eg,

    $ whtest http://my/url?arg={0} --mode=stream --list=mylist

In this case the input list is intrepreted as a list of input arguments
to be included in the URL. Ie, before a request is issued whtest replaces
all occurrences of the token '{0}' in the URL with a URL-encoded version
of the corresponding item in the input list.

By default requests are issued in the order they appear in the file. To
alter the order whtest provides the --select option which can take one
of the following values:

     normal:  select items from the input list in order
    shuffle:  apply a random shuffle operation to the input list
      cycle:  each client cycles the list by one

these operations are applied to the input list for each simulated client.
Finally, whtest will try to honor the --min-req and --max-req options 
when dealing with lists. If the input list has less than --min-req items,
whtest will pad the input list before applying the --select method. If
the list has more than --max-req items whtest truncates the list as
needed.

-----------------------------------------------------------------------------
STREAMING
-----------------------------------------------------------------------------
The switches --chunk-bytes and --chunk-interval control the rate at which
a file is POST'ed to a server. By default these parameters are set to 
values suitable for single rate, AMR-encoded audio files.

Note that one can simulate a standard, non-streaming POST by selecting a
large enough chunk size.

-----------------------------------------------------------------------------
OUTPUT
-----------------------------------------------------------------------------
When whtest completes it generates two cumulative histograms, one for
connection times and the second for response latencies. These capture the
total number of requests that fall below the given time. Eg, the following
output shows that all 5 connections (100%) were completed in 0.01 seconds,
that 2 requests (40%) had a response latency of 0.035 sec, and that all
requests had a response latency of less than or equal to 0.037 sec.

    HTTP Client Test
    DATE: 2009-03-08 15:11:55.543101
    URL: http://localhost:8080/nlu?text={0}

    Conn Time Histogram
    --------------------------------
       00.000 sec:    3 ( 60%)
       00.000 sec:    4 ( 80%)
       00.000 sec:    4 ( 80%)
       00.000 sec:    4 ( 80%)
       00.001 sec:    5 (100%)

    Latency Histogram
    --------------------------------
       00.030 sec:    1 ( 20%)
       00.031 sec:    1 ( 20%)
       00.033 sec:    1 ( 20%)
       00.035 sec:    2 ( 40%)
       00.037 sec:    5 (100%)

    --------------------------------
    Total Requests: 5

The connection time captures the time a simulated client takes to make a
TCP connection. The response latency measures how long it took the server
to send back a response. Response latencies are always measured from the
time the last byte of a request was sent (ie, for streaming requests the
timer is started when the last stream chunk is transmitted).

whtest can also print a simple report with the requests it issued during
a test and each of the responses it received. To print the report use
the --report switch:

    $ whtest http://myurl --report=myreport.txt

Finally, whtest provides a tracing facility that can be used to provide
more detail while the test is running. To increate the level of detail
use the --trace-level option. Eg,

    $ whtest http://myurl --trace-level=debug

-----------------------------------------------------------------------------
REGRESSION TESTING
-----------------------------------------------------------------------------
The --reference switch provides a mechanism for whtest to check the responses
sent by the server and compare them to expected responses. In addition, 
the --res-handler switch lets users provide their own functions for parsing
the HTTP body and for comparing the parsed body to a corresponding reference.
Eg,

    $ whtest http://my/url?arg={0} my_input_list.txt --mode=text \\
               --reference=myrefs.txt \\
               --res-handler=myhandler.py
               
where the file 'myhandler.py' is a Python file with two functions that
must have the following signatures:
    
    def parse(headers, body):
        metrics = {}
        return body, metrics

    def match(parsed_text, reference):
        return True
        
The 'parse' function takes a list of header-value tuples and a string with
the body of the HTTP response; it should return a new string with the parsed
result and a dictionary with any metrics information. The 'match' function
takes the parsed result and the corresponding reference item as argument and
should return True or False as appropriate. The default parse and match
handlers are meant to work with WATSON's JSON format for ASR requests.

'''

# ============================================================================
#
import sys, os, socket, errno, time, random, urllib, re
import urlparse, StringIO, email, copy, datetime, signal
import xml.dom.minidom as minidom
import threading, logging, traceback, inspect

# ============================================================================
# common trace log
#
LOG = logging.getLogger('main')
LOG.addHandler(logging.StreamHandler(sys.stdout))

# ============================================================================
# command line option parsing
#
def buildOptionParser ():

    from optparse import OptionParser

    version = "%s: %s\n" % (PROG_NAME, PROG_VERSION)
    usage = "%s url inputlist" % PROG_NAME
    description = "%s is a utility to stress test a server over HTTP" % PROG_NAME

    oparser = OptionParser(usage=usage, description=description, version=version)

    oparser.add_option('--doc', action='store_true', dest='doc', 
                       default=False,
                       help="print documentation")
    oparser.add_option('--input', action='store', type='string', dest='inputItem',
                       default=None,
                       help="input item [None]")
    oparser.add_option('--list', action='store', type='string', dest='inputList',
                       default=None,
                       help="list file with one input item per line [None]")
    oparser.add_option('--num-threads', action='store', type='int', dest='numThreads',
                       default=1,
                       help="number of concurrent clients (ie, threads) [1]")
    oparser.add_option('--header', action='append', type='string', dest='headers', 
                       default=[],
                       help="additional HTTP headers")
    oparser.add_option('--mode', action='store', type='string', dest='mode',
                       default='text',
                       help="input mode; stream|text [stream]")
    oparser.add_option('--select', action='store', type='string', dest='select',
                       default='normal',
                       help="input selection method; normal|shuffle|cycle [normal]")
    oparser.add_option('--min-req', action='store', type='int', dest='minReq',
                       default=1,
                       help="minimum number of requests per thread")
    oparser.add_option('--max-req', action='store', type='int', dest='maxReq',
                       default=None,
                       help="maximum number of requests per thread")
    oparser.add_option('--reference', action='store', type='string', dest='refs',
                       default=None,
                       help="optional list of references for match caclulation")
    oparser.add_option('--res-handler', action='store', type='string', dest='resHandler',
                       default=None,
                       help="Python file with custom result evaluation functions")
    oparser.add_option('--report', action='store', type='string', dest='report',
                       default=None,
                       help="save test report to specified file [None]")
    oparser.add_option('--chunk-bytes', action='store', type='int', dest='bytesPerTx',
                       default=385,
                       help="bytes per chunk [385]")
    oparser.add_option('--chunk-interval', action='store', type='float', dest='txInterval',
                       default=0.250,
                       help="delay between chunks in sec [0.250]")
    oparser.add_option('--req-delay', action='store', type='float', dest='reqDelay',
                       default=0.5,
                       help="max random delay between requests [0.5 sec]")
    oparser.add_option('--hist', action='append', dest='histograms',
                       default=[],
                       help="specify additional histograms to print to stdout")
    oparser.add_option('--hist-size', action='store', type='float', dest='histSize',
                       default=5,
                       help="number of histogram buckets [5]")
    oparser.add_option('--trace-level', action='store', type='string', dest='traceLevel',
                       default='warning',
                       help='one of error, warning, info or debug [warning]')

    return oparser

# ============================================================================
# initialize the trace logging object
#
def initialize_trace (level_str):
    try:
        levels = { 'debug'   : logging.DEBUG,
                   'info'    : logging.INFO,
                   'warning' : logging.WARNING,
                   'error'   : logging.ERROR }
        if level_str.lower() not in levels:
            raise RuntimeError, "invalid trace level [%s]" % level_str
        level = levels[level_str.lower()]
        l = logging.getLogger('main')
        f = logging.Formatter('%(asctime)s %(threadName)s %(message)s')
        l.handlers[0].setFormatter(f)
        l.setLevel(level)
    except Exception, e:
        if LOG.level == logging.DEBUG:
            e_type, e_value, e_tb = sys.exc_info()
            tb_str = ''.join(traceback.format_exception(e_type, e_value, e_tb))
            LOG.debug('ERROR: %s\n' % tb_str)
        sys.stderr.write('%s ERROR: %s\n' % (PROG_NAME, e))
        sys.exit(1)

# ============================================================================
# extract the item of interest from the result. By default assume we're
# getting JSON with a results[0].reco property, and possibly a metrics
# property; if it fails we just return the raw text.
#
def result_parse(headers, body):
    metrics = {}
    parse = body
    try:
        res = eval(body)
        if 'metrics' in res and type(res['metrics']) is dict:
            metrics = res['metrics']
            for k in metrics.keys():
                metrics[k] = metrics[k].split()[0]
        # one-best result
        parse = res["results"][0]
    except Exception, e:
        pass
    return parse, metrics

# ============================================================================
# compare result to reference; return True if the reference
# text is anywhere in the returned text
#
def result_match(res_text, ref_text):
    match = False
    try:
        match = (res_text.find(ref_text) >= 0)
    except Exception, e:
        pass
    return match

# ============================================================================
# tasks contain a list of requests plus some meta data common to
# all of the requests (chunk size, tx interval, target URL, etc).
#
class Task(object):
    __slots__ = ('mode', 'url', 'headers', 'requests', 
                 'bytesPerTx', 'txInterval', 'reqDelay')
    def __init__ (self, mode, url, headers, requests, 
                        bytesPerTx, txInterval, reqDelay):
        assert (mode in ['text', 'stream'])
        self.mode = mode
        self.url = url
        self.headers = headers
        self.requests = requests
        self.bytesPerTx = bytesPerTx
        self.txInterval = txInterval
        self.reqDelay = reqDelay

# ============================================================================
# input to a request and its optional reference transcription
#
class Request(object):
    __slots__ = ('rinput', 'reference', 'result')
    def __init__ (self, i, r):
        self.rinput = i
        self.reference = r
        self.result = None

# ============================================================================
# on completion of each request we get one of these objects
#
class Result(object):
    __slots__ = ('bytesTx', 'connTime', 'txTime', 'resTime', 
                 'raw', 'body', 'headers')
    def __init__ (self):
        self.bytesTx = 0
        self.connTime = 0.0
        self.txTime = 0.0
        self.resTime = 0.0
        self.raw = '' 
        self.body = ''
        self.headers = []

# ============================================================================
# parse a list of input items and, optionally, an accompanying list of
# reference transcriptions; checks that each file in the list exists;
# returns a list of Request objects; if there are less than min_req
# input items pad the list with items starting from the front.
#
def parse_input_list (mode, input_item, list_path, ref_path, min_req, max_req):
    assert (mode in ['text', 'stream'])
    if not input_item and not list_path:
        # special case; simple text queries can make do with just a URL
        if mode == 'text':
            return min_req * [Request(None, None)]
        raise RuntimeError, 'input item or input list is required'
    # input items can be file paths or input strings    
    input_items = []
    if not list_path:
        assert(input_item)
        input_items.append(input_item)
    else:
        list_path = os.path.abspath(list_path)
        list_dir = os.path.dirname(list_path)
        if not os.path.isfile(list_path):
            raise RuntimeError, "no such list file [%s]" % list_path
        for p in open(list_path, 'r'):
            p = p.strip()
            if not p: continue
            if not os.path.isabs(p):
                p = os.path.join(list_dir, p)
            input_items.append(p)
    # in stream mode the input items are file paths
    if mode == 'stream':
        for p in input_items:
            if not os.path.isfile(p):
                raise RuntimeError, "stream file does not exist [%s]" % p
    # refs are optional
    references = [None] * len(input_items)
    if ref_path:
        references = []
        for r in open(ref_path, 'r'):
            r = r.strip()
            if not r: continue
            references.append(r)
    if len(input_items) != len(references):
        raise RuntimeError, "input items and references do not match"
    # raw input list; cut down to size or pad as needed
    rlist = [Request(i, j) for i, j in zip(input_items, references)]
    if max_req:
        # cut
        rlist = rlist[:max_req]
    elif min_req:
        # pad
        n = 0
        while len(rlist) < min_req:
            # need new objs, not refs to existing objs
            rlist.append(copy.deepcopy(rlist[n]))
            n += 1
    # done
    return rlist

# ============================================================================
# generate a histogram from a list of numbers
#
def gen_histogram (items, num_buckets):
    assert(items and num_buckets > 0)
    hist = {}
    # make sure we get floats
    items = [float(i) for i in items]
    items.sort()
    min_i = items[0]
    max_i = items[-1]
    bucket_inc = (max_i - min_i) / num_buckets
    fmt = '%06.2f'
    if bucket_inc < 0.01: fmt = '%06.3f'
    for i in range(1, num_buckets + 1):
        bucket = min_i + bucket_inc * i
        if i == num_buckets:
            bucket = max_i
        hist[bucket] = 0
        for i in items:
            if i <= bucket:
                hist[bucket] += 1
    return hist

# ============================================================================
# connect to server URL; returns tuple (socket, host, url_path, conn_t)
#
def url_connect (url):
    url_parts = urlparse.urlparse(url)
    if url_parts[0].lower() != 'http':
        raise RuntimeError, "only HTTP URLs are supported [%s]" % url
    host_port = url_parts[1].split(':')
    serverHost = host_port[0]
    serverPort = 80
    if len(host_port) > 1: serverPort = int(host_port[1])
    urlPath = url_parts[2] + '?' + url_parts[4]
    # connect to server
    connect_t = time.time()
    svrsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    svrsock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
    rv = svrsock.connect_ex( (serverHost, serverPort) )
    connect_t = time.time() - connect_t
    if rv != 0:
        s = errno.errorcode[rv]
        raise RuntimeError, "connection to %s:%d failed [%s]" % (serverHost, serverPort, s)
    return svrsock, serverHost, urlPath, connect_t

# ============================================================================
# read a single HTTP response; returns the response and the time it took for
# it to arrive in a tuple (resp, wait_t); we try to look for a content length
# header in the first chunk of a response and if we find it, we read only that
# many bytes; if no content length header is found we read to EOF.
#
def get_http_response (sock):
    resp = StringIO.StringIO()
    start_t = time.time()
    first_byte_t = time.time()
    nbytes = 0
    content_len = -1
    while True:
        b = ''
        try:
            b = sock.recv(2056)
        except socket.error, e:
            if e[0] != errno.ECONNRESET: raise
        if not b:
            break
        if nbytes == 0:
            first_byte_t = time.time() - start_t 
        nbytes += len(b)
        resp.write(b)
        # check if we're done reading the response headers (the HTTP spec
        # requires a double \r\n sequence to terminate the headers).
        v = resp.getvalue()
        if content_len < 0 and v.find('\r\n\r\n') > 0:
            try: content_len = int(re.search('^Content-Length\s*:(.*)$', v, re.M|re.I).group(1))
            except: pass
            LOG.debug("Content Length: %s" % content_len)
        # don't wait for EOF if we don't have to
        if content_len >= 0 and nbytes >= content_len:
            break
    if content_len < 0:
        LOG.warning("response had no content length")
    total_t = time.time() - start_t
    v = resp.getvalue()
    #if not v:
    #    raise RuntimeError, "server disconnected"
    return v, first_byte_t, total_t

# ============================================================================
# parse an HTTP response and return the data and content type
# of the enclosed MIME message (if any)
#
def parse_http_response (r):
    assert(type(r) == str)
    r = r.split('\n', 1)
    if len (r) != 2:
        raise RuntimeError, "bad HTTP message: %s" % r
    status_line, mime_body = r
    status_line = status_line.split(None, 2)
    if len(status_line) != 3:
        raise RuntimeError, "bad HTTP status line: %s" % status_line
    httpver, httpcode, httpmsg = status_line
    m = email.message_from_string(mime_body)
    content_type = m.get_content_type().lower().strip()
    payload = m.get_payload()
    headers = m.items()
    if httpcode != "200" and httpcode != "205":
        raise RuntimeError, "HTTP error %s: %s\n%s" % (httpcode, httpmsg, payload)
    return payload, headers

# ============================================================================
# process an stream request; stream a file to server URL in chunks of
# bytesPerTx bytes with a delay between chunks of txInterval seconds
#
def do_stream_request (rinput, url, headers, bytesPerTx, txInterval):
    assert(rinput and bytesPerTx > 0 and txInterval > 0)
    rsize = os.stat(rinput).st_size
    LOG.debug("stream: %s (%d bytes)" % (rinput, rsize))
    # connect to server
    svrsock, host, url_path, conn_t = url_connect(url)
    # send HTTP request headers
    svrsock.sendall("POST %s HTTP/1.1\r\n" % url_path)
    svrsock.sendall("User-Agent: %s/%s\r\n" % (PROG_NAME, PROG_VERSION))
    svrsock.sendall("Host: %s\r\n" % host)
    svrsock.sendall("Transfer-Encoding: chunked\r\n")
    svrsock.sendall("Connection: close\r\n")
    # custom headers
    set_content_type = True
    for h in headers:
        h = h.strip()
        if re.match('^content-type\s*:.*$', h, re.M|re.I):
            set_content_type = False
        svrsock.sendall("%s\r\n" % h)
    # only set content type if it isn't already provided
    if set_content_type:
        svrsock.sendall("Content-Type: application/octet-stream\r\n")
    # no more headers
    svrsock.sendall("\r\n")
    # sleep can not be depended on for precise intervals as it puts us at the
    # mercy of the kernel scheduler - we try to do some corrections here but
    # this only helps somewhat
    auf = open(rinput, 'rb')
    current_interval = 0
    bytes_tx = 0
    tx_t = time.time()
    try:
        while True:
            start_t = time.time()
            time.sleep(current_interval)
            buf = auf.read(bytesPerTx)
            if not buf: 
                break
            # chunked encoding: chunk length, data, empty line
            bytes_tx += len(buf)
            svrsock.sendall('%x\r\n' % len(buf))
            svrsock.sendall(buf)
            svrsock.sendall('\r\n')
            if len(buf) < bytesPerTx: 
                break
            # adjust the next interval by the amount we overran this one.
            elapsed = time.time() - start_t
            overrun = elapsed - current_interval
            current_interval = txInterval - overrun
            if current_interval < 0:
                current_interval = 0
        # end of stream is marked by a zero length chunk
        svrsock.sendall('%x\r\n' % 0)
        svrsock.sendall('\r\n')
    except socket.error, e:
        # we don't want errors early in the stream to keep us
        # from getting the HTTP error response below
        if e[0] not in [errno.EPIPE, errno.ECONNRESET]:
            raise e
    LOG.debug("request issued (%d bytes)" % bytes_tx)
    # make note of how long it took to stream the file 
    tx_t = time.time() - tx_t
    # sit and wait for the response
    resp, first_t, total_t = get_http_response(svrsock)
    LOG.debug("response, %d bytes, first_t %.3f sec, total_t %.3f sec" % (len(resp), first_t, total_t))
    # parse response
    body, headers = parse_http_response(resp)
    # make sure the client machine isn't lagging
    stream_len = float(rsize) / bytesPerTx * txInterval
    if abs(tx_t - stream_len) > stream_len * 0.10:
        LOG.warning("stream transmission falling behind")
    # finito
    r = Result()
    r.bytesTx = bytes_tx
    r.connTime = conn_t
    r.txTime = tx_t
    r.resTime = total_t
    r.raw = resp
    r.body = body
    r.headers = headers
    return r

# ============================================================================
# process a text GET request; replace (case sensitive) any occurrence
# of the string {0} with the current input, rinput. This scheme extends
# naturally if in the future we allow pipe-delimited lines in the
# the items file.
#
def do_text_request (rinput, url, headers):
    if rinput is not None:
        rinput = urllib.quote(rinput)
        url = url.replace('{0}', rinput)
    # connect to server
    svrsock, host, url_path, conn_t = url_connect(url)
    # send HTTP request
    buf = "GET %s HTTP/1.1\r\n" % url_path
    svrsock.sendall(buf)
    # basic headers
    svrsock.sendall("User-Agent: %s/%s\r\n" % (PROG_NAME, PROG_VERSION))
    svrsock.sendall("Host: %s\r\n" % host)
    svrsock.sendall("Connection: close\r\n")
    # custom headers
    for h in headers: svrsock.sendall("%s\r\n" % h)
    svrsock.sendall("\r\n")
    # sit and wait for the response
    LOG.debug("request issued")
    resp, first_t, total_t = get_http_response(svrsock)
    LOG.debug("response, %d bytes, first_t %.3f sec, total_t %.3f sec" % (len(resp), first_t, total_t))
    # parse response
    body, headers = parse_http_response(resp)
    # finito
    r = Result()
    r.bytesTx = len(buf)
    r.connTime = conn_t
    r.txTime = 0.0
    r.resTime = total_t
    r.raw = resp
    r.body = body
    r.headers = headers
    return r

# ============================================================================
# processes a list of requests
#
def process_task (task):
    for req in task.requests:
        try:
            delay_sec = task.reqDelay * random.random()
            if delay_sec > 0:
                LOG.debug ("delay %.3f sec" % delay_sec)
            time.sleep(delay_sec)
            if task.mode in ['stream']:
                req.result = do_stream_request(req.rinput, task.url, task.headers,
                                               task.bytesPerTx, task.txInterval)
            else:
                req.result = do_text_request(req.rinput, task.url, task.headers)
            res = req.result
            msg  = '\n'
            msg += "INPUT: %s\n" % req.rinput
            msg += "LATENCY: conn_t %.3f sec | res_t %.3f sec\n" % (res.connTime, res.resTime)
            if LOG.level == logging.DEBUG:
                msg += "RESPONSE:\n%s\n" % res.raw
                LOG.debug(msg)
            else:
                LOG.info(msg)            
        except Exception, e:
            if LOG.level == logging.DEBUG:
                e_type, e_value, e_tb = sys.exc_info()
                tb_str = ''.join(traceback.format_exception(e_type, e_value, e_tb))
                LOG.debug('ERROR:\n%s' % tb_str)
            else:
                LOG.error("ERROR:\n%s\n" % e)
            # killing the process here avoids corrupted log output below
            os.kill(os.getpid(), signal.SIGKILL)
    LOG.debug("task complete")

# ============================================================================
# prints metrics info
#
def print_metrics (f, metrics, hist_size, total, mismatches):
    for mk, mv in metrics.items():
        mv = [float(v) for v in mv]
        f.write ('\n')
        f.write ('--------------------------------\n')
        f.write ('%s\n' % mk)
        f.write ('\n')
        h = gen_histogram(mv, hist_size)
        keys = h.keys()
        keys.sort()
        for k in keys:
            pct = '%d%%' % int(float(h[k])/total*100)
            f.write ('   %06.3f: %4d (%s)\n' % (k, h[k], pct.rjust(4)))
        f.write ('\n')
        f.write (' Count: %d\n' % len(mv))
        f.write ('   Avg: %.3f\n' % (sum(mv)/len(mv)))
        f.write ('   Max: %.3f\n' % (max(mv)))
        f.write ('   Min: %.3f\n' % (min(mv)))
    f.write ('\n')
    f.write ('--------------------------------\n')
    f.write ('Result String Match\n\n')
    f.write ('   Total: %d\n' % total)
    f.write ('   Mismatches: %d\n' % mismatches)
    f.write ('\n')

# ============================================================================
# Execution starts here
#
if __name__ == '__main__':

    oparser = buildOptionParser()
    (opts, args) = oparser.parse_args(sys.argv)

    if opts.doc:
        print doc
        sys.exit(0)
        
    try:
        if len(args) != 2:
            raise RuntimeError, "bad argument count"
            
        if opts.maxReq and opts.maxReq < opts.minReq:
            raise RuntimeError, "max-req cannot be less than min-req"

        mode = opts.mode.lower()
        if mode == 'audio': mode = 'stream'
        if mode not in ['text', 'stream']:
            raise RuntimeError, "mode must be 'text' or 'stream'"

        if opts.inputItem and opts.inputList:
            raise RuntimeError, "--input and --list cannot be used together"

        url = args[1]

        initialize_trace(opts.traceLevel)

        # creates a list of Request objects
        input_list = parse_input_list(mode, opts.inputItem, opts.inputList,
                                      opts.refs, opts.minReq, opts.maxReq)

        # define handlers responsible for parsing server responses for useful
        # info and checking if the response matches the reference; use our
        # handler functions by default, but allow user to override
        r_parse = result_parse
        r_match = result_match
        if opts.resHandler:
            global_ns = { 'LOG' : LOG }
            execfile(opts.resHandler, global_ns)
            f = global_ns.get('parse')
            if not f or not inspect.isfunction(f):
                raise RuntimeError, "handler file [%s] has no parse() func" % opts.resHandler
            r_parse = f
            f = global_ns.get('match')
            if not f or not inspect.isfunction(f):
                raise RuntimeError, "handler file [%s] has no match() func" % opts.resHandler
            r_match = f

        # spin up the requisite number of threads; assign to each thread a
        # copy of the input list and apply a cycle, a shuffle or nothing
        # to each thread's copy.
        threads = []
        for i in range(opts.numThreads):
            requests = copy.deepcopy(input_list)
            if opts.select == 'random' :
                random.shuffle(requests)
            elif opts.select == 'cycle':
                requests = requests[i:] + requests[:i]
            task = Task(opts.mode, url, opts.headers, requests, opts.bytesPerTx,
                        opts.txInterval, opts.reqDelay)
            t = threading.Thread(target=process_task, args=[task])
            t.task = task
            t.setDaemon(True)
            t.start()
            threads.append(t)

        # wait for them to finish
        while True:
            for t in threads:
                if t.isAlive():
                    t.join(0.50); break
            alive = 0
            for t in threads:
                if t.isAlive(): alive += 1
            if alive == 0: break

        # collect the results
        metrics = {}
        latencies = []
        conn_times = []
        total = len(input_list) * opts.numThreads
        mismatches = 0
        report = open('/dev/null', 'w')
        if opts.report: report = open(opts.report, 'w')
        for t in threads:
            for req in t.task.requests:
                res = req.result
                latencies.append(res.resTime)
                conn_times.append(res.connTime)
                # did we get what we wanted?
                parsed_body, m  = r_parse(res.headers, res.body)
                # accumulate metrics
                for k, v in m.items():
                    metrics.setdefault(k, []).append(v)
                # did we get what we were looking for?
                mismatch = False
                if req.reference and not r_match(parsed_body, req.reference): 
                    mistmach = True
                    mismatches += 1
                report.write('INPUT: %s\n' % req.rinput)
                report.write('MISMATCH: %s\n' % mismatch)
                report.write('LATENCY: conn_t %.3f sec | resp_t %.3f sec\n' % (res.connTime, res.resTime))
                report.write('RESPONSE: \n%s\n' % res.raw)
                if parsed_body != res.body:
                    report.write('\nPARSED BODY: \n%s\n' % parsed_body)
                if req.reference:
                    report.write('\nREFERENCE: \n%s\n' % req.reference)
                report.write('\n' + 80 * '=' + '\n\n')
        # our metrics have higher priority
        metrics['resp_latency'] = latencies
        metrics['conn_time'] = conn_times

        # opening output message
        report_hdr  = 'WATSON HTTP Client Test\n\n'
        report_hdr += '   date: %s\n' % datetime.datetime.now()
        report_hdr += '   url: %s\n' % url
        report_hdr += "   mode: %s\n" % opts.mode
        report_hdr += "   threads: %s\n" % opts.numThreads
        report_hdr += "   requests/thread: %d\n" % len(input_list)
        report_hdr += "   select method: %s\n" % opts.select
        report_hdr += "   req delay: %.3f sec\n" % opts.reqDelay        
        report_hdr += "   bytes/chunk: %d\n" % opts.bytesPerTx
        report_hdr += "   chunk interval: %.3f sec\n" % opts.txInterval
        report_hdr += "   result handler: %s\n" % opts.resHandler
        report_hdr += "   input item: %s\n" % opts.inputItem
        report_hdr += "   input list: %s\n" % opts.inputList
        # print summary to report file
        report.write('\n')
        report.write(report_hdr)
        print_metrics(report, metrics, opts.histSize, total, mismatches)
        # select which histograms to print to the console (response
        # latency is mandatory)
        which = opts.histograms + ['resp_latency']
        for k in metrics.keys():
            if k not in which: del metrics[k]
        # and always to the console
        sys.stdout.write('--------------------------------\n')
        sys.stdout.write(report_hdr)
        print_metrics(sys.stdout, metrics, opts.histSize, total, mismatches)

    except KeyboardInterrupt:
        LOG.info('ctrl-C detected. Exiting...')
        os.kill(os.getpid(), signal.SIGKILL)

    except Exception, e:
        if LOG.level == logging.DEBUG:
            e_type, e_value, e_tb = sys.exc_info()
            tb_str = ''.join(traceback.format_exception(e_type, e_value, e_tb))
            LOG.debug('ERROR: %s\n' % tb_str)
        sys.stderr.write('%s ERROR: %s\n' % (PROG_NAME, e))
        sys.exit(1)


